{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5bd4c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T16:12:03.780520Z",
     "iopub.status.busy": "2021-10-01T16:12:03.775057Z",
     "iopub.status.idle": "2021-10-01T16:13:37.804035Z",
     "shell.execute_reply": "2021-10-01T16:13:37.803227Z",
     "shell.execute_reply.started": "2021-10-01T05:52:49.383875Z"
    },
    "papermill": {
     "duration": 94.060465,
     "end_time": "2021-10-01T16:13:37.804257",
     "exception": false,
     "start_time": "2021-10-01T16:12:03.743792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/glmcdona/LuxPythonEnvGym.git\r\n",
      "  Cloning https://github.com/glmcdona/LuxPythonEnvGym.git to /tmp/pip-req-build-jiltard8\r\n",
      "  Running command git clone -q https://github.com/glmcdona/LuxPythonEnvGym.git /tmp/pip-req-build-jiltard8\r\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from luxai2021==0.1.0) (6.2.4)\r\n",
      "Collecting stable_baselines3\r\n",
      "  Downloading stable_baselines3-1.2.0-py3-none-any.whl (161 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 161 kB 725 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from luxai2021==0.1.0) (1.19.5)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from luxai2021==0.1.0) (2.4.1)\r\n",
      "Requirement already satisfied: gym in /opt/conda/lib/python3.7/site-packages (from luxai2021==0.1.0) (0.18.3)\r\n",
      "Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym->luxai2021==0.1.0) (1.5.15)\r\n",
      "Requirement already satisfied: Pillow<=8.2.0 in /opt/conda/lib/python3.7/site-packages (from gym->luxai2021==0.1.0) (8.2.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from gym->luxai2021==0.1.0) (1.6.3)\r\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym->luxai2021==0.1.0) (1.6.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest->luxai2021==0.1.0) (20.9)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->luxai2021==0.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from pytest->luxai2021==0.1.0) (0.10.2)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->luxai2021==0.1.0) (3.4.0)\r\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest->luxai2021==0.1.0) (1.10.0)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->luxai2021==0.1.0) (21.2.0)\r\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->luxai2021==0.1.0) (0.13.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->luxai2021==0.1.0) (3.4.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->luxai2021==0.1.0) (3.7.4.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytest->luxai2021==0.1.0) (2.4.7)\r\n",
      "Collecting torch>=1.8.1\r\n",
      "  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 831.4 MB 3.8 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable_baselines3->luxai2021==0.1.0) (3.4.2)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from stable_baselines3->luxai2021==0.1.0) (1.2.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable_baselines3->luxai2021==0.1.0) (1.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable_baselines3->luxai2021==0.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable_baselines3->luxai2021==0.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->stable_baselines3->luxai2021==0.1.0) (1.15.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->stable_baselines3->luxai2021==0.1.0) (2021.1)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (3.17.3)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (0.36.2)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (1.32.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (0.4.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (3.3.4)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (1.30.2)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (1.8.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (0.12.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (2.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->luxai2021==0.1.0) (2.25.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->luxai2021==0.1.0) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->luxai2021==0.1.0) (4.7.2)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->luxai2021==0.1.0) (4.2.2)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->luxai2021==0.1.0) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->luxai2021==0.1.0) (0.4.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->luxai2021==0.1.0) (1.26.5)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->luxai2021==0.1.0) (2021.5.30)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->luxai2021==0.1.0) (4.0.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->luxai2021==0.1.0) (2.10)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->luxai2021==0.1.0) (3.1.1)\r\n",
      "Building wheels for collected packages: luxai2021\r\n",
      "  Building wheel for luxai2021 (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for luxai2021: filename=luxai2021-0.1.0-py3-none-any.whl size=39158 sha256=63a3e6d2b23166e1e13082266a7b9dc44e6a6483526e850ce3d69defd6d6d34b\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pieh5q1j/wheels/b2/22/ee/884dd4091817cdc45e2980f439823344fb99cad2a54fa05e65\r\n",
      "Successfully built luxai2021\r\n",
      "Installing collected packages: torch, stable-baselines3, luxai2021\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.7.0\r\n",
      "    Uninstalling torch-1.7.0:\r\n",
      "      Successfully uninstalled torch-1.7.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\r\n",
      "fastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.1 which is incompatible.\r\n",
      "allennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\r\n",
      "Successfully installed luxai2021-0.1.0 stable-baselines3-1.2.0 torch-1.9.1\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Requirement already satisfied: kaggle-environments in /opt/conda/lib/python3.7/site-packages (1.7.11)\r\n",
      "Collecting kaggle-environments\r\n",
      "  Downloading kaggle_environments-1.8.12-py2.py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 706 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kaggle-environments) (3.2.0)\r\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (1.15.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (21.2.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (0.17.3)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (3.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.1->kaggle-environments) (3.7.4.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.1->kaggle-environments) (3.4.1)\r\n",
      "Installing collected packages: kaggle-environments\r\n",
      "  Attempting uninstall: kaggle-environments\r\n",
      "    Found existing installation: kaggle-environments 1.7.11\r\n",
      "    Uninstalling kaggle-environments-1.7.11:\r\n",
      "      Successfully uninstalled kaggle-environments-1.7.11\r\n",
      "Successfully installed kaggle-environments-1.8.12\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/glmcdona/LuxPythonEnvGym.git\n",
    "!pip install kaggle-environments -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078a2b1",
   "metadata": {
    "papermill": {
     "duration": 0.372527,
     "end_time": "2021-10-01T16:13:38.577803",
     "exception": false,
     "start_time": "2021-10-01T16:13:38.205276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Use GPU if available\n",
    "Note: GPU provides very little speedup. I recommend using a CPU-only notebook usually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2768098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T16:13:39.309391Z",
     "iopub.status.busy": "2021-10-01T16:13:39.308660Z",
     "iopub.status.idle": "2021-10-01T16:13:40.124159Z",
     "shell.execute_reply": "2021-10-01T16:13:40.124644Z",
     "shell.execute_reply.started": "2021-10-01T05:53:06.821749Z"
    },
    "papermill": {
     "duration": 1.19075,
     "end_time": "2021-10-01T16:13:40.124832",
     "exception": false,
     "start_time": "2021-10-01T16:13:38.934082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0267d",
   "metadata": {
    "papermill": {
     "duration": 0.357767,
     "end_time": "2021-10-01T16:13:40.840755",
     "exception": false,
     "start_time": "2021-10-01T16:13:40.482988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the RL agent logic\n",
    "Edit this agent logic to implement your own observations, action space, and reward shaping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec43eb9",
   "metadata": {
    "papermill": {
     "duration": 0.358717,
     "end_time": "2021-10-01T16:13:41.557024",
     "exception": false,
     "start_time": "2021-10-01T16:13:41.198307",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc98eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T16:13:42.324217Z",
     "iopub.status.busy": "2021-10-01T16:13:42.321689Z",
     "iopub.status.idle": "2021-10-01T16:13:42.328750Z",
     "shell.execute_reply": "2021-10-01T16:13:42.329319Z",
     "shell.execute_reply.started": "2021-10-01T05:53:06.83207Z"
    },
    "papermill": {
     "duration": 0.406318,
     "end_time": "2021-10-01T16:13:42.329505",
     "exception": false,
     "start_time": "2021-10-01T16:13:41.923187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting agent_policy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agent_policy.py\n",
    "from luxai2021.game.match_controller import ActionSequence\n",
    "import sys\n",
    "import time\n",
    "from functools import partial  # pip install functools\n",
    "\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from luxai2021.env.agent import Agent\n",
    "from luxai2021.game.actions import *\n",
    "from luxai2021.game.game_constants import GAME_CONSTANTS\n",
    "from luxai2021.game.position import Position\n",
    "\n",
    "\n",
    "# https://codereview.stackexchange.com/questions/28207/finding-the-closest-point-to-a-list-of-points\n",
    "def closest_node(node, nodes):\n",
    "    dist_2 = np.sum((nodes - node) ** 2, axis=1)\n",
    "    return np.argmin(dist_2)\n",
    "def furthest_node(node, nodes):\n",
    "    dist_2 = np.sum((nodes - node) ** 2, axis=1)\n",
    "    return np.argmax(dist_2)\n",
    "\n",
    "def smart_transfer_to_nearby(game, team, unit_id, unit, target_type_restriction=None, **kwarg):\n",
    "    \"\"\"\n",
    "    Smart-transfers from the specified unit to a nearby neighbor. Prioritizes any\n",
    "    nearby carts first, then any worker. Transfers the resource type which the unit\n",
    "    has most of. Picks which cart/worker based on choosing a target that is most-full\n",
    "    but able to take the most amount of resources.\n",
    "\n",
    "    Args:\n",
    "        team ([type]): [description]\n",
    "        unit_id ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        Action: Returns a TransferAction object, even if the request is an invalid\n",
    "                transfer. Use TransferAction.is_valid() to check validity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate how much resources could at-most be transferred\n",
    "    resource_type = None\n",
    "    resource_amount = 0\n",
    "    target_unit = None\n",
    "\n",
    "    if unit != None:\n",
    "        for type, amount in unit.cargo.items():\n",
    "            if amount > resource_amount:\n",
    "                resource_type = type\n",
    "                resource_amount = amount\n",
    "\n",
    "        # Find the best nearby unit to transfer to\n",
    "        unit_cell = game.map.get_cell_by_pos(unit.pos)\n",
    "        adjacent_cells = game.map.get_adjacent_cells(unit_cell)\n",
    "\n",
    "        \n",
    "        for c in adjacent_cells:\n",
    "            for id, u in c.units.items():\n",
    "                # Apply the unit type target restriction\n",
    "                if target_type_restriction == None or u.type == target_type_restriction:\n",
    "                    if u.team == team:\n",
    "                        # This unit belongs to our team, set it as the winning transfer target\n",
    "                        # if it's the best match.\n",
    "                        if target_unit is None:\n",
    "                            target_unit = u\n",
    "                        else:\n",
    "                            # Compare this unit to the existing target\n",
    "                            if target_unit.type == u.type:\n",
    "                                # Transfer to the target with the least capacity, but can accept\n",
    "                                # all of our resources\n",
    "                                if( u.get_cargo_space_left() >= resource_amount and \n",
    "                                    target_unit.get_cargo_space_left() >= resource_amount ):\n",
    "                                    # Both units can accept all our resources. Prioritize one that is most-full.\n",
    "                                    if u.get_cargo_space_left() < target_unit.get_cargo_space_left():\n",
    "                                        # This new target it better, it has less space left and can take all our\n",
    "                                        # resources\n",
    "                                        target_unit = u\n",
    "                                    \n",
    "                                elif( target_unit.get_cargo_space_left() >= resource_amount ):\n",
    "                                    # Don't change targets. Current one is best since it can take all\n",
    "                                    # the resources, but new target can't.\n",
    "                                    pass\n",
    "                                    \n",
    "                                elif( u.get_cargo_space_left() > target_unit.get_cargo_space_left() ):\n",
    "                                    # Change targets, because neither target can accept all our resources and \n",
    "                                    # this target can take more resources.\n",
    "                                    target_unit = u\n",
    "                            elif u.type == Constants.UNIT_TYPES.CART:\n",
    "                                # Transfer to this cart instead of the current worker target\n",
    "                                target_unit = u\n",
    "    \n",
    "    # Build the transfer action request\n",
    "    target_unit_id = None\n",
    "    if target_unit is not None:\n",
    "        target_unit_id = target_unit.id\n",
    "\n",
    "        # Update the transfer amount based on the room of the target\n",
    "        if target_unit.get_cargo_space_left() < resource_amount:\n",
    "            resource_amount = target_unit.get_cargo_space_left()\n",
    "    \n",
    "    return TransferAction(team, unit_id, target_unit_id, resource_type, resource_amount)\n",
    "\n",
    "########################################################################################################################\n",
    "# This is the Agent that you need to design for the competition\n",
    "########################################################################################################################\n",
    "class AgentPolicy(Agent):\n",
    "    def __init__(self, mode=\"train\", model=None) -> None:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            mode: \"train\" or \"inference\", which controls if this agent is for training or not.\n",
    "            model: The pretrained model, or if None it will operate in training mode.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.stats = None\n",
    "        self.stats_last_game = None\n",
    "\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        self.actionSpaceMapUnits = [\n",
    "            partial(MoveAction, direction=Constants.DIRECTIONS.CENTER),  # This is the do-nothing action\n",
    "            partial(MoveAction, direction=Constants.DIRECTIONS.NORTH),\n",
    "            partial(MoveAction, direction=Constants.DIRECTIONS.WEST),\n",
    "            partial(MoveAction, direction=Constants.DIRECTIONS.SOUTH),\n",
    "            partial(MoveAction, direction=Constants.DIRECTIONS.EAST),\n",
    "            smart_transfer_to_nearby, # Transfer to nearby\n",
    "            SpawnCityAction,\n",
    "            #PillageAction,\n",
    "        ]\n",
    "        self.actionSpaceMapCities = [\n",
    "            SpawnWorkerAction,\n",
    "            SpawnCartAction,\n",
    "            ResearchAction,\n",
    "        ]\n",
    "\n",
    "        self.action_space = spaces.Discrete(max(len(self.actionSpaceMapUnits), len(self.actionSpaceMapCities)))\n",
    "        \n",
    "\n",
    "        # Observation space: (Basic minimum for a miner agent)\n",
    "        # Object:\n",
    "        #   1x is worker\n",
    "        #   1x is cart\n",
    "        #   1x is citytile\n",
    "        #\n",
    "        #   5x direction_nearest_wood\n",
    "        #   1x distance_nearest_wood\n",
    "        #   1x amount\n",
    "        #\n",
    "        #   5x direction_nearest_coal\n",
    "        #   1x distance_nearest_coal\n",
    "        #   1x amount\n",
    "        #\n",
    "        #   5x direction_nearest_uranium\n",
    "        #   1x distance_nearest_uranium\n",
    "        #   1x amount\n",
    "        #\n",
    "        #   5x direction_nearest_city\n",
    "        #   1x distance_nearest_city\n",
    "        #   1x amount of fuel\n",
    "        #\n",
    "        #   28x (the same as above, but direction, distance, and amount to the furthest of each)\n",
    "        #\n",
    "        #   5x direction_nearest_worker\n",
    "        #   1x distance_nearest_worker\n",
    "        #   1x amount of cargo\n",
    "        # Unit:\n",
    "        #   1x cargo size\n",
    "        # State:\n",
    "        #   1x is night\n",
    "        #   1x percent of game done\n",
    "        #   2x citytile counts [cur player, opponent]\n",
    "        #   2x worker counts [cur player, opponent]\n",
    "        #   2x cart counts [cur player, opponent]\n",
    "        #   1x research points [cur player]\n",
    "        #   1x researched coal [cur player]\n",
    "        #   1x researched uranium [cur player]\n",
    "        self.observation_shape = (3 + 7 * 5 * 2 + 1 + 1 + 1 + 2 + 2 + 2 + 3,)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=\n",
    "        self.observation_shape, dtype=np.float16)\n",
    "\n",
    "        self.object_nodes = {}\n",
    "\n",
    "    def get_agent_type(self):\n",
    "        \"\"\"\n",
    "        Returns the type of agent. Use AGENT for inference, and LEARNING for training a model.\n",
    "        \"\"\"\n",
    "        if self.mode == \"train\":\n",
    "            return Constants.AGENT_TYPE.LEARNING\n",
    "        else:\n",
    "            return Constants.AGENT_TYPE.AGENT\n",
    "\n",
    "    def get_observation(self, game, unit, city_tile, team, is_new_turn):\n",
    "        \"\"\"\n",
    "        Implements getting a observation from the current game for this unit or city\n",
    "        \"\"\"\n",
    "        observation_index = 0\n",
    "        if is_new_turn:\n",
    "            # It's a new turn this event. This flag is set True for only the first observation from each turn.\n",
    "            # Update any per-turn fixed observation space that doesn't change per unit/city controlled.\n",
    "\n",
    "            # Build a list of object nodes by type for quick distance-searches\n",
    "            self.object_nodes = {}\n",
    "\n",
    "            # Add resources\n",
    "            for cell in game.map.resources:\n",
    "                if cell.resource.type not in self.object_nodes:\n",
    "                    self.object_nodes[cell.resource.type] = np.array([[cell.pos.x, cell.pos.y]])\n",
    "                else:\n",
    "                    self.object_nodes[cell.resource.type] = np.concatenate(\n",
    "                        (\n",
    "                            self.object_nodes[cell.resource.type],\n",
    "                            [[cell.pos.x, cell.pos.y]]\n",
    "                        ),\n",
    "                        axis=0\n",
    "                    )\n",
    "\n",
    "            # Add your own and opponent units\n",
    "            for t in [team, (team + 1) % 2]:\n",
    "                for u in game.state[\"teamStates\"][team][\"units\"].values():\n",
    "                    key = str(u.type)\n",
    "                    if t != team:\n",
    "                        key = str(u.type) + \"_opponent\"\n",
    "\n",
    "                    if key not in self.object_nodes:\n",
    "                        self.object_nodes[key] = np.array([[u.pos.x, u.pos.y]])\n",
    "                    else:\n",
    "                        self.object_nodes[key] = np.concatenate(\n",
    "                            (\n",
    "                                self.object_nodes[key],\n",
    "                                [[u.pos.x, u.pos.y]]\n",
    "                            )\n",
    "                            , axis=0\n",
    "                        )\n",
    "\n",
    "            # Add your own and opponent cities\n",
    "            for city in game.cities.values():\n",
    "                for cells in city.city_cells:\n",
    "                    key = \"city\"\n",
    "                    if city.team != team:\n",
    "                        key = \"city_opponent\"\n",
    "\n",
    "                    if key not in self.object_nodes:\n",
    "                        self.object_nodes[key] = np.array([[cells.pos.x, cells.pos.y]])\n",
    "                    else:\n",
    "                        self.object_nodes[key] = np.concatenate(\n",
    "                            (\n",
    "                                self.object_nodes[key],\n",
    "                                [[cells.pos.x, cells.pos.y]]\n",
    "                            )\n",
    "                            , axis=0\n",
    "                        )\n",
    "\n",
    "        # Observation space: (Basic minimum for a miner agent)\n",
    "        # Object:\n",
    "        #   1x is worker\n",
    "        #   1x is cart\n",
    "        #   1x is citytile\n",
    "        #   5x direction_nearest_wood\n",
    "        #   1x distance_nearest_wood\n",
    "        #   1x amount\n",
    "        #\n",
    "        #   5x direction_nearest_coal\n",
    "        #   1x distance_nearest_coal\n",
    "        #   1x amount\n",
    "        #\n",
    "        #   5x direction_nearest_uranium\n",
    "        #   1x distance_nearest_uranium\n",
    "        #   1x amount\n",
    "        #\n",
    "        #   5x direction_nearest_city\n",
    "        #   1x distance_nearest_city\n",
    "        #   1x amount of fuel\n",
    "        #\n",
    "        #   5x direction_nearest_worker\n",
    "        #   1x distance_nearest_worker\n",
    "        #   1x amount of cargo\n",
    "        #\n",
    "        #   28x (the same as above, but direction, distance, and amount to the furthest of each)\n",
    "        #\n",
    "        # Unit:\n",
    "        #   1x cargo size\n",
    "        # State:\n",
    "        #   1x is night\n",
    "        #   1x percent of game done\n",
    "        #   2x citytile counts [cur player, opponent]\n",
    "        #   2x worker counts [cur player, opponent]\n",
    "        #   2x cart counts [cur player, opponent]\n",
    "        #   1x research points [cur player]\n",
    "        #   1x researched coal [cur player]\n",
    "        #   1x researched uranium [cur player]\n",
    "        obs = np.zeros(self.observation_shape)\n",
    "        \n",
    "        # Update the type of this object\n",
    "        #   1x is worker\n",
    "        #   1x is cart\n",
    "        #   1x is citytile\n",
    "        observation_index = 0\n",
    "        if unit is not None:\n",
    "            if unit.type == Constants.UNIT_TYPES.WORKER:\n",
    "                obs[observation_index] = 1.0 # Worker\n",
    "            else:\n",
    "                obs[observation_index+1] = 1.0 # Cart\n",
    "        if city_tile is not None:\n",
    "            obs[observation_index+2] = 1.0 # CityTile\n",
    "        observation_index += 3\n",
    "        \n",
    "        pos = None\n",
    "        if unit is not None:\n",
    "            pos = unit.pos\n",
    "        else:\n",
    "            pos = city_tile.pos\n",
    "\n",
    "        if pos is None:\n",
    "            observation_index += 7 * 5 * 2\n",
    "        else:\n",
    "            # Encode the direction to the nearest objects\n",
    "            #   5x direction_nearest\n",
    "            #   1x distance\n",
    "            for distance_function in [closest_node, furthest_node]:\n",
    "                for key in [\n",
    "                    Constants.RESOURCE_TYPES.WOOD,\n",
    "                    Constants.RESOURCE_TYPES.COAL,\n",
    "                    Constants.RESOURCE_TYPES.URANIUM,\n",
    "                    \"city\",\n",
    "                    str(Constants.UNIT_TYPES.WORKER)]:\n",
    "                    # Process the direction to and distance to this object type\n",
    "\n",
    "                    # Encode the direction to the nearest object (excluding itself)\n",
    "                    #   5x direction\n",
    "                    #   1x distance\n",
    "                    if key in self.object_nodes:\n",
    "                        if (\n",
    "                                (key == \"city\" and city_tile is not None) or\n",
    "                                (unit is not None and str(unit.type) == key and len(game.map.get_cell_by_pos(unit.pos).units) <= 1 )\n",
    "                        ):\n",
    "                            # Filter out the current unit from the closest-search\n",
    "                            closest_index = closest_node((pos.x, pos.y), self.object_nodes[key])\n",
    "                            filtered_nodes = np.delete(self.object_nodes[key], closest_index, axis=0)\n",
    "                        else:\n",
    "                            filtered_nodes = self.object_nodes[key]\n",
    "\n",
    "                        if len(filtered_nodes) == 0:\n",
    "                            # No other object of this type\n",
    "                            obs[observation_index + 5] = 1.0\n",
    "                        else:\n",
    "                            # There is another object of this type\n",
    "                            closest_index = distance_function((pos.x, pos.y), filtered_nodes)\n",
    "\n",
    "                            if closest_index is not None and closest_index >= 0:\n",
    "                                closest = filtered_nodes[closest_index]\n",
    "                                closest_position = Position(closest[0], closest[1])\n",
    "                                direction = pos.direction_to(closest_position)\n",
    "                                mapping = {\n",
    "                                    Constants.DIRECTIONS.CENTER: 0,\n",
    "                                    Constants.DIRECTIONS.NORTH: 1,\n",
    "                                    Constants.DIRECTIONS.WEST: 2,\n",
    "                                    Constants.DIRECTIONS.SOUTH: 3,\n",
    "                                    Constants.DIRECTIONS.EAST: 4,\n",
    "                                }\n",
    "                                obs[observation_index + mapping[direction]] = 1.0  # One-hot encoding direction\n",
    "\n",
    "                                # 0 to 1 distance\n",
    "                                distance = pos.distance_to(closest_position)\n",
    "                                obs[observation_index + 5] = min(distance / 20.0, 1.0)\n",
    "\n",
    "                                # 0 to 1 value (amount of resource, cargo for unit, or fuel for city)\n",
    "                                if key == \"city\":\n",
    "                                    # City fuel as % of upkeep for 200 turns\n",
    "                                    c = game.cities[game.map.get_cell_by_pos(closest_position).city_tile.city_id]\n",
    "                                    obs[observation_index + 6] = min(\n",
    "                                        c.fuel / (c.get_light_upkeep() * 200.0),\n",
    "                                        1.0\n",
    "                                    )\n",
    "                                elif key in [Constants.RESOURCE_TYPES.WOOD, Constants.RESOURCE_TYPES.COAL,\n",
    "                                             Constants.RESOURCE_TYPES.URANIUM]:\n",
    "                                    # Resource amount\n",
    "                                    obs[observation_index + 6] = min(\n",
    "                                        game.map.get_cell_by_pos(closest_position).resource.amount / 500,\n",
    "                                        1.0\n",
    "                                    )\n",
    "                                else:\n",
    "                                    # Unit cargo\n",
    "                                    obs[observation_index + 6] = min(\n",
    "                                        next(iter(game.map.get_cell_by_pos(\n",
    "                                            closest_position).units.values())).get_cargo_space_left() / 100,\n",
    "                                        1.0\n",
    "                                    )\n",
    "\n",
    "                    observation_index += 7\n",
    "\n",
    "        if unit is not None:\n",
    "            # Encode the cargo space\n",
    "            #   1x cargo size\n",
    "            obs[observation_index] = unit.get_cargo_space_left() / GAME_CONSTANTS[\"PARAMETERS\"][\"RESOURCE_CAPACITY\"][\n",
    "                \"WORKER\"]\n",
    "            observation_index += 1\n",
    "        else:\n",
    "            observation_index += 1\n",
    "\n",
    "        # Game state observations\n",
    "\n",
    "        #   1x is night\n",
    "        obs[observation_index] = game.is_night()\n",
    "        observation_index += 1\n",
    "\n",
    "        #   1x percent of game done\n",
    "        obs[observation_index] = game.state[\"turn\"] / GAME_CONSTANTS[\"PARAMETERS\"][\"MAX_DAYS\"]\n",
    "        observation_index += 1\n",
    "\n",
    "        #   2x citytile counts [cur player, opponent]\n",
    "        #   2x worker counts [cur player, opponent]\n",
    "        #   2x cart counts [cur player, opponent]\n",
    "        max_count = 30\n",
    "        for key in [\"city\", str(Constants.UNIT_TYPES.WORKER), str(Constants.UNIT_TYPES.CART)]:\n",
    "            if key in self.object_nodes:\n",
    "                obs[observation_index] = len(self.object_nodes[key]) / max_count\n",
    "            if (key + \"_opponent\") in self.object_nodes:\n",
    "                obs[observation_index + 1] = len(self.object_nodes[(key + \"_opponent\")]) / max_count\n",
    "            observation_index += 2\n",
    "\n",
    "        #   1x research points [cur player]\n",
    "        #   1x researched coal [cur player]\n",
    "        #   1x researched uranium [cur player]\n",
    "        obs[observation_index] = game.state[\"teamStates\"][team][\"researchPoints\"] / 200.0\n",
    "        obs[observation_index+1] = float(game.state[\"teamStates\"][team][\"researched\"][\"coal\"])\n",
    "        obs[observation_index+2] = float(game.state[\"teamStates\"][team][\"researched\"][\"uranium\"])\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def action_code_to_action(self, action_code, game, unit=None, city_tile=None, team=None):\n",
    "        \"\"\"\n",
    "        Takes an action in the environment according to actionCode:\n",
    "            actionCode: Index of action to take into the action array.\n",
    "        Returns: An action.\n",
    "        \"\"\"\n",
    "        # Map actionCode index into to a constructed Action object\n",
    "        try:\n",
    "            x = None\n",
    "            y = None\n",
    "            if city_tile is not None:\n",
    "                x = city_tile.pos.x\n",
    "                y = city_tile.pos.y\n",
    "            elif unit is not None:\n",
    "                x = unit.pos.x\n",
    "                y = unit.pos.y\n",
    "            \n",
    "            if city_tile != None:\n",
    "                action =  self.actionSpaceMapCities[action_code%len(self.actionSpaceMapCities)](\n",
    "                    game=game,\n",
    "                    unit_id=unit.id if unit else None,\n",
    "                    unit=unit,\n",
    "                    city_id=city_tile.city_id if city_tile else None,\n",
    "                    citytile=city_tile,\n",
    "                    team=team,\n",
    "                    x=x,\n",
    "                    y=y\n",
    "                )\n",
    "\n",
    "                # If the city action is invalid, default to research action automatically\n",
    "                if not action.is_valid(game, actions_validated=[]):\n",
    "                    action = ResearchAction(\n",
    "                        game=game,\n",
    "                        unit_id=unit.id if unit else None,\n",
    "                        unit=unit,\n",
    "                        city_id=city_tile.city_id if city_tile else None,\n",
    "                        citytile=city_tile,\n",
    "                        team=team,\n",
    "                        x=x,\n",
    "                        y=y\n",
    "                    )\n",
    "            else:\n",
    "                action =  self.actionSpaceMapUnits[action_code%len(self.actionSpaceMapUnits)](\n",
    "                    game=game,\n",
    "                    unit_id=unit.id if unit else None,\n",
    "                    unit=unit,\n",
    "                    city_id=city_tile.city_id if city_tile else None,\n",
    "                    citytile=city_tile,\n",
    "                    team=team,\n",
    "                    x=x,\n",
    "                    y=y\n",
    "                )\n",
    "            \n",
    "            return action\n",
    "        except Exception as e:\n",
    "            # Not a valid action\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def take_action(self, action_code, game, unit=None, city_tile=None, team=None):\n",
    "        \"\"\"\n",
    "        Takes an action in the environment according to actionCode:\n",
    "            actionCode: Index of action to take into the action array.\n",
    "        \"\"\"\n",
    "        action = self.action_code_to_action(action_code, game, unit, city_tile, team)\n",
    "        self.match_controller.take_action(action)\n",
    "    \n",
    "    def game_start(self, game):\n",
    "        \"\"\"\n",
    "        This funciton is called at the start of each game. Use this to\n",
    "        reset and initialize per game. Note that self.team may have\n",
    "        been changed since last game. The game map has been created\n",
    "        and starting units placed.\n",
    "\n",
    "        Args:\n",
    "            game ([type]): Game.\n",
    "        \"\"\"\n",
    "        self.last_generated_fuel = game.stats[\"teamStats\"][self.team][\"fuelGenerated\"]\n",
    "        self.last_resources_collected = copy.deepcopy(game.stats[\"teamStats\"][self.team][\"resourcesCollected\"])\n",
    "        if self.stats != None:\n",
    "            self.stats_last_game =  self.stats\n",
    "        self.stats = {\n",
    "            \"rew/r_total\": 0,\n",
    "            \"rew/r_wood\": 0,\n",
    "            \"rew/r_coal\": 0,\n",
    "            \"rew/r_uranium\": 0,\n",
    "            \"rew/r_research\": 0,\n",
    "            \"rew/r_city_tiles_end\": 0,\n",
    "            \"rew/r_fuel_collected\":0,\n",
    "            \"rew/r_units\":0,\n",
    "            \"rew/r_city_tiles\":0,\n",
    "            \"game/turns\": 0,\n",
    "            \"game/research\": 0,\n",
    "            \"game/unit_count\": 0,\n",
    "            \"game/cart_count\": 0,\n",
    "            \"game/city_count\": 0,\n",
    "            \"game/city_tiles\": 0,\n",
    "            \"game/wood_rate_mined\": 0,\n",
    "            \"game/coal_rate_mined\": 0,\n",
    "            \"game/uranium_rate_mined\": 0,\n",
    "        }\n",
    "        self.is_last_turn = False\n",
    "\n",
    "        # Calculate starting map resources\n",
    "        type_map = {\n",
    "            Constants.RESOURCE_TYPES.WOOD: \"WOOD\",\n",
    "            Constants.RESOURCE_TYPES.COAL: \"COAL\",\n",
    "            Constants.RESOURCE_TYPES.URANIUM: \"URANIUM\",\n",
    "        }\n",
    "\n",
    "        self.fuel_collected_last = 0\n",
    "        self.fuel_start = {}\n",
    "        self.fuel_last = {}\n",
    "        for type, type_upper in type_map.items():\n",
    "            self.fuel_start[type] = 0\n",
    "            self.fuel_last[type] = 0\n",
    "            for c in game.map.resources_by_type[type]:\n",
    "                self.fuel_start[type] += c.resource.amount * game.configs[\"parameters\"][\"RESOURCE_TO_FUEL_RATE\"][type_upper]\n",
    "\n",
    "        self.research_last = 0\n",
    "        self.units_last = 0\n",
    "        self.city_tiles_last = 0\n",
    "\n",
    "    def get_reward(self, game, is_game_finished, is_new_turn, is_game_error):\n",
    "        \"\"\"\n",
    "        Returns the reward function for this step of the game.\n",
    "        \"\"\"\n",
    "        if is_game_error:\n",
    "            # Game environment step failed, assign a game lost reward to not incentivise this\n",
    "            print(\"Game failed due to error\")\n",
    "            return -1.0\n",
    "\n",
    "        if not is_new_turn and not is_game_finished:\n",
    "            # Only apply rewards at the start of each turn\n",
    "            return 0\n",
    "\n",
    "        # Get some basic stats\n",
    "        unit_count = len(game.state[\"teamStates\"][self.team % 2][\"units\"])\n",
    "        cart_count = 0\n",
    "        for id, u in game.state[\"teamStates\"][self.team % 2][\"units\"].items():\n",
    "            if u.type == Constants.UNIT_TYPES.CART:\n",
    "                cart_count += 1\n",
    "\n",
    "        unit_count_opponent = len(game.state[\"teamStates\"][(self.team + 1) % 2][\"units\"])\n",
    "        research = min(game.state[\"teamStates\"][self.team][\"researchPoints\"], 200.0) # Cap research points at 200\n",
    "        city_count = 0\n",
    "        city_count_opponent = 0\n",
    "        city_tile_count = 0\n",
    "        city_tile_count_opponent = 0\n",
    "        for city in game.cities.values():\n",
    "            if city.team == self.team:\n",
    "                city_count += 1\n",
    "            else:\n",
    "                city_count_opponent += 1\n",
    "\n",
    "            for cell in city.city_cells:\n",
    "                if city.team == self.team:\n",
    "                    city_tile_count += 1\n",
    "                else:\n",
    "                    city_tile_count_opponent += 1\n",
    "        \n",
    "        # Basic stats\n",
    "        self.stats[\"game/research\"] = research\n",
    "        self.stats[\"game/city_tiles\"] = city_tile_count\n",
    "        self.stats[\"game/city_count\"] = city_count\n",
    "        self.stats[\"game/unit_count\"] = unit_count\n",
    "        self.stats[\"game/cart_count\"] = cart_count\n",
    "        self.stats[\"game/turns\"] = game.state[\"turn\"]\n",
    "\n",
    "        rewards = {}\n",
    "\n",
    "        # Give up to 1.0 reward for each resource based on % of total mined.\n",
    "        type_map = {\n",
    "            Constants.RESOURCE_TYPES.WOOD: \"WOOD\",\n",
    "            Constants.RESOURCE_TYPES.COAL: \"COAL\",\n",
    "            Constants.RESOURCE_TYPES.URANIUM: \"URANIUM\",\n",
    "        }\n",
    "        fuel_now = {}\n",
    "        for type, type_upper in type_map.items():\n",
    "            fuel_now = game.stats[\"teamStats\"][self.team][\"resourcesCollected\"][type] * game.configs[\"parameters\"][\"RESOURCE_TO_FUEL_RATE\"][type_upper]\n",
    "            rewards[\"rew/r_%s\" % type] = (fuel_now - self.fuel_last[type]) / self.fuel_start[type]\n",
    "            self.stats[\"game/%s_rate_mined\" % type] = fuel_now / self.fuel_start[type]\n",
    "            self.fuel_last[type] = fuel_now\n",
    "        \n",
    "        # Give more incentive for coal and uranium\n",
    "        rewards[\"rew/r_%s\" % Constants.RESOURCE_TYPES.COAL] *= 2\n",
    "        rewards[\"rew/r_%s\" % Constants.RESOURCE_TYPES.URANIUM] *= 4\n",
    "        \n",
    "        # Give a reward based on amount of fuel collected. 1.0 reward for each 20K fuel gathered.\n",
    "        fuel_collected = game.stats[\"teamStats\"][self.team][\"fuelGenerated\"]\n",
    "        rewards[\"rew/r_fuel_collected\"] = ( (fuel_collected - self.fuel_collected_last) / 20000 )\n",
    "        self.fuel_collected_last = fuel_collected\n",
    "\n",
    "        # Give a reward for unit creation/death. 0.05 reward per unit.\n",
    "        rewards[\"rew/r_units\"] = (unit_count - self.units_last) * 0.05\n",
    "        self.units_last = unit_count\n",
    "\n",
    "        # Give a reward for unit creation/death. 0.1 reward per city.\n",
    "        rewards[\"rew/r_city_tiles\"] = (city_tile_count - self.city_tiles_last) * 0.1\n",
    "        self.city_tiles_last = city_tile_count\n",
    "\n",
    "        # Tiny reward for research to help. Up to 0.5 reward for this.\n",
    "        rewards[\"rew/r_research\"] = (research - self.research_last) / (200 * 2)\n",
    "        self.research_last = research\n",
    "        \n",
    "        # Give a reward up to around 50.0 based on number of city tiles at the end of the game\n",
    "        rewards[\"rew/r_city_tiles_end\"] = 0\n",
    "        if is_game_finished:\n",
    "            self.is_last_turn = True\n",
    "            rewards[\"rew/r_city_tiles_end\"] = city_tile_count\n",
    "        \n",
    "        \n",
    "        # Update the stats and total reward\n",
    "        reward = 0\n",
    "        for name, value in rewards.items():\n",
    "            self.stats[name] += value\n",
    "            reward += value\n",
    "        self.stats[\"rew/r_total\"] += reward\n",
    "\n",
    "        # Print the final game stats sometimes\n",
    "        if is_game_finished and random.random() <= 0.15:\n",
    "            stats_string = []\n",
    "            for key, value in self.stats.items():\n",
    "                stats_string.append(\"%s=%.2f\" % (key, value))\n",
    "            print(\",\".join(stats_string))\n",
    "\n",
    "\n",
    "        return reward\n",
    "        \n",
    "    \n",
    "\n",
    "    def process_turn(self, game, team):\n",
    "        \"\"\"\n",
    "        Decides on a set of actions for the current turn. Not used in training, only inference.\n",
    "        Returns: Array of actions to perform.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        actions = []\n",
    "        new_turn = True\n",
    "\n",
    "        # Inference the model per-unit\n",
    "        units = game.state[\"teamStates\"][team][\"units\"].values()\n",
    "        for unit in units:\n",
    "            if unit.can_act():\n",
    "                obs = self.get_observation(game, unit, None, unit.team, new_turn)\n",
    "                action_code, _states = self.model.predict(obs, deterministic=False)\n",
    "                if action_code is not None:\n",
    "                    actions.append(\n",
    "                        self.action_code_to_action(action_code, game=game, unit=unit, city_tile=None, team=unit.team))\n",
    "                new_turn = False\n",
    "\n",
    "        # Inference the model per-city\n",
    "        cities = game.cities.values()\n",
    "        for city in cities:\n",
    "            if city.team == team:\n",
    "                for cell in city.city_cells:\n",
    "                    city_tile = cell.city_tile\n",
    "                    if city_tile.can_act():\n",
    "                        obs = self.get_observation(game, None, city_tile, city.team, new_turn)\n",
    "                        action_code, _states = self.model.predict(obs, deterministic=False)\n",
    "                        if action_code is not None:\n",
    "                            actions.append(\n",
    "                                self.action_code_to_action(action_code, game=game, unit=None, city_tile=city_tile,\n",
    "                                                           team=city.team))\n",
    "                        new_turn = False\n",
    "\n",
    "        time_taken = time.time() - start_time\n",
    "        if time_taken > 0.5:  # Warn if larger than 0.5 seconds.\n",
    "            print(\"WARNING: Inference took %.3f seconds for computing actions. Limit is 1 second.\" % time_taken,\n",
    "                  file=sys.stderr)\n",
    "\n",
    "        return actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167a0df",
   "metadata": {
    "papermill": {
     "duration": 0.395787,
     "end_time": "2021-10-01T16:13:43.135254",
     "exception": false,
     "start_time": "2021-10-01T16:13:42.739467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build the environment for training\n",
    "\n",
    "Notes on metrics:\n",
    "* An Episode is a single game between your RL agent and it's opponent. This is generally 360 turns, spanning more than 360 unit + city decision steps.\n",
    "* Mean episode length (ep_len_mean) is the number of decision made per game. The larger this gets, means that it is making more unit + city decision per game, meaning that more units and cities were alive for longer during the game.\n",
    "* Episode reward mean (ep_rew_mean), is set up as micro-reward funciton for faster learning. Per turn it gets a small reward based on the number of cities and units alive. It gets a really big reward based on the number of cities and units alive at the end of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc439466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T16:13:43.927479Z",
     "iopub.status.busy": "2021-10-01T16:13:43.924975Z",
     "iopub.status.idle": "2021-10-01T16:13:44.636424Z",
     "shell.execute_reply": "2021-10-01T16:13:44.635695Z",
     "shell.execute_reply.started": "2021-10-01T05:53:06.853365Z"
    },
    "papermill": {
     "duration": 1.135744,
     "end_time": "2021-10-01T16:13:44.636587",
     "exception": false,
     "start_time": "2021-10-01T16:13:43.500843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in inference-only mode.\n",
      "C:\\Users\\saite\\LuxPythonEnvGym\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from typing import Callable\n",
    "\n",
    "from stable_baselines3 import PPO  # pip install stable-baselines3\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "from importlib import reload\n",
    "import agent_policy\n",
    "reload(agent_policy) # Reload the file from disk incase the above agent-writing cell block was edited\n",
    "from agent_policy import AgentPolicy\n",
    "\n",
    "from luxai2021.env.agent import Agent\n",
    "from luxai2021.env.lux_env import LuxEnvironment\n",
    "from luxai2021.game.constants import LuxMatchConfigs_Default\n",
    "\n",
    "\n",
    "# Default Lux configs\n",
    "configs = LuxMatchConfigs_Default\n",
    "\n",
    "# Create a default opponent agent\n",
    "opponent = Agent()\n",
    "\n",
    "# Create a RL agent in training mode\n",
    "player = AgentPolicy(mode=\"train\")\n",
    "\n",
    "# Create the Lux environment\n",
    "env = LuxEnvironment(configs=configs,\n",
    "                     learning_agent=player,\n",
    "                     opponent_agent=opponent)\n",
    "\n",
    "# Define the model, you can pick other RL algos from Stable Baselines3 instead if you like\n",
    "model = PPO(\"MlpPolicy\",\n",
    "                env,\n",
    "                verbose=1,\n",
    "                tensorboard_log=\"./lux_tensorboard/\",\n",
    "                learning_rate=0.001,\n",
    "                gamma=0.999,\n",
    "                gae_lambda=0.95,\n",
    "                batch_size=2048 * 8,\n",
    "                n_steps=2048 * 8\n",
    "            )\n",
    "\n",
    "# Define a learning rate schedule\n",
    "# (number of steps, learning_rate)\n",
    "schedule = [\n",
    "    #(2000000, 0.01),\n",
    "    (6000, 0.001),\n",
    "    #(6000000, 0.0001),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3830c7",
   "metadata": {
    "papermill": {
     "duration": 0.369884,
     "end_time": "2021-10-01T16:13:45.368322",
     "exception": false,
     "start_time": "2021-10-01T16:13:44.998438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the agent against a dummy opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e343602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T16:13:46.107107Z",
     "iopub.status.busy": "2021-10-01T16:13:46.106333Z",
     "iopub.status.idle": "2021-10-01T21:49:04.939917Z",
     "shell.execute_reply": "2021-10-01T21:49:04.940666Z",
     "shell.execute_reply.started": "2021-10-01T05:53:06.91014Z"
    },
    "papermill": {
     "duration": 20119.210493,
     "end_time": "2021-10-01T21:49:04.940908",
     "exception": false,
     "start_time": "2021-10-01T16:13:45.730415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Logging to ./lux_tensorboard/PPO_1\n",
      "rew/r_total=0.02,rew/r_wood=0.01,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=31.00,game/research=5.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.01,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.02,rew/r_wood=0.01,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=32.00,game/research=4.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.01,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.03,rew/r_wood=0.02,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=35.00,game/research=5.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.02,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.01,rew/r_wood=0.00,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=31.00,game/research=4.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.00,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.08,rew/r_wood=0.05,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.01,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=111.00,game/research=8.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.05,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.01,rew/r_wood=0.00,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=31.00,game/research=4.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.00,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.04,rew/r_wood=0.02,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=157.00,game/research=6.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.02,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.06,rew/r_wood=0.04,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.01,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=72.00,game/research=7.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.04,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.10,rew/r_wood=0.07,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.01,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=39.00,game/research=6.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.07,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.02,rew/r_wood=0.01,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=32.00,game/research=5.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.01,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.08,rew/r_wood=0.04,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.01,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=78.00,game/research=10.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.04,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.07,rew/r_wood=0.04,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.01,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=116.00,game/research=6.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.04,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.18,rew/r_wood=0.13,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.04,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.01,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=311.00,game/research=17.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.13,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.03,rew/r_wood=0.01,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.01,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=111.00,game/research=5.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.01,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.07,rew/r_wood=0.05,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=116.00,game/research=8.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.05,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.01,rew/r_wood=0.00,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=31.00,game/research=4.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.00,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.16,rew/r_wood=0.08,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.03,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.05,rew/r_city_tiles=0.00,game/turns=198.00,game/research=12.00,game/unit_count=1.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.08,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.06,rew/r_wood=0.03,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=191.00,game/research=9.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.03,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.08,rew/r_wood=0.06,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=112.00,game/research=8.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.06,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.02,rew/r_wood=0.01,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=31.00,game/research=5.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.01,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.11,rew/r_wood=0.04,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.02,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.05,rew/r_city_tiles=0.00,game/turns=198.00,game/research=7.00,game/unit_count=1.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.04,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "rew/r_total=0.20,rew/r_wood=0.12,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.07,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.01,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=311.00,game/research=26.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.12,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rew/r_total=0.02,rew/r_wood=0.01,rew/r_coal=0.00,rew/r_uranium=0.00,rew/r_research=0.01,rew/r_city_tiles_end=0.00,rew/r_fuel_collected=0.00,rew/r_units=0.00,rew/r_city_tiles=0.00,game/turns=111.00,game/research=4.00,game/unit_count=0.00,game/cart_count=0.00,game/city_count=0.00,game/city_tiles=0.00,game/wood_rate_mined=0.01,game/coal_rate_mined=0.00,game/uranium_rate_mined=0.00\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 119      |\n",
      "|    ep_rew_mean     | 0.178    |\n",
      "| time/              |          |\n",
      "|    fps             | 425      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 19943    |\n",
      "---------------------------------\n",
      "Done training model.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.utils import get_schedule_fn\n",
    "\n",
    "print(\"Training model...\")\n",
    "run_id = 1\n",
    "\n",
    "# Save a checkpoint every 1M steps\n",
    "checkpoint_callback = CheckpointCallback(save_freq=1000,\n",
    "                                         save_path='./models1/',\n",
    "                                         name_prefix=f'rl_model_{run_id}')\n",
    "\n",
    "# Train the policy\n",
    "for steps, learning_rate in schedule:\n",
    "    model.lr_schedule = get_schedule_fn(learning_rate)\n",
    "    model.learn(total_timesteps=steps,\n",
    "                callback=checkpoint_callback,\n",
    "                reset_num_timesteps = False)\n",
    "\n",
    "# Save final model\n",
    "model.save(path=f'models/model.zip')\n",
    "\n",
    "print(\"Done training model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20280.275823,
   "end_time": "2021-10-01T21:49:55.405250",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-01T16:11:55.129427",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
